{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
        "from tensorflow.keras.layers import Dense, Input, Reshape, Conv2DTranspose, Conv2D, Flatten\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from moviepy.editor import VideoClip, TextClip\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "hgaQh16wfzeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextToVideoGenerator:\n",
        "    def __init__(self, gpt_model_path=\"gpt2\", latent_dim=100):\n",
        "        self.tokenizer = GPT2Tokenizer.from_pretrained(gpt_model_path)\n",
        "        self.gpt_model = TFGPT2LMHeadModel.from_pretrained(gpt_model_path)\n",
        "        self.gan = GAN(latent_dim=latent_dim)\n",
        "\n",
        "    def text_to_embedding(self, text):\n",
        "        inputs = self.tokenizer(text, return_tensors=\"tf\", max_length=1024, truncation=True)\n",
        "        outputs = self.gpt_model(inputs[\"input_ids\"])\n",
        "        return outputs.last_hidden_state[:, -1, :]\n",
        "\n",
        "    def generate_video(self, quotes, output_path='output.mp4', duration_per_quote=5, fps=24):\n",
        "        frames = []\n",
        "        for quote in quotes:\n",
        "            embedding = self.text_to_embedding(quote)\n",
        "            latent_noise = np.random.normal(size=(1, self.gan.latent_dim))\n",
        "            generated_video = self.gan.generator.predict(latent_noise)\n",
        "\n",
        "            frame_clip = VideoClip(lambda t: generated_video, duration=duration_per_quote)\n",
        "            text_clip = TextClip(quote, fontsize=24, color='white', bg_color='black').set_pos('center').set_duration(duration_per_quote)\n",
        "\n",
        "            final_clip = VideoClip(composite_video_clip, size=(generated_video.shape[1], generated_video.shape[2]))\n",
        "            frames.append(final_clip)\n",
        "\n",
        "        final_video = concatenate_videoclips(frames, method=\"compose\")\n",
        "        final_video.write_videofile(output_path, codec='libx264', audio_codec='aac', fps=fps)"
      ],
      "metadata": {
        "id": "uNvrA-DXf9G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GAN:\n",
        "    def __init__(self, latent_dim=100, img_shape=(64, 64, 3)):\n",
        "        self.latent_dim = latent_dim\n",
        "        self.img_shape = img_shape\n",
        "        self.generator = self.build_generator()\n",
        "        self.discriminator = self.build_discriminator()\n",
        "        self.gan = self.build_gan()\n",
        "\n",
        "    def build_generator(self):\n",
        "        model = Sequential([\n",
        "            Dense(128, input_dim=self.latent_dim),\n",
        "            Reshape((1, 1, 128)),\n",
        "            Conv2DTranspose(128, (4, 4), strides=(2, 2), padding=\"same\", activation=\"relu\"),\n",
        "            Conv2DTranspose(64, (4, 4), strides=(2, 2), padding=\"same\", activation=\"relu\"),\n",
        "            Conv2DTranspose(3, (4, 4), strides=(2, 2), padding=\"same\", activation=\"sigmoid\"),\n",
        "        ])\n",
        "        return model\n",
        "\n",
        "    def build_discriminator(self):\n",
        "        model = Sequential([\n",
        "            Conv2D(64, (4, 4), strides=(2, 2), padding=\"same\", input_shape=self.img_shape, activation=\"relu\"),\n",
        "            Conv2D(128, (4, 4), strides=(2, 2), padding=\"same\", activation=\"relu\"),\n",
        "            Flatten(),\n",
        "            Dense(1, activation=\"sigmoid\"),\n",
        "        ])\n",
        "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "        return model\n",
        "\n",
        "    def build_gan(self):\n",
        "        self.discriminator.trainable = False\n",
        "        gan_input = Input(shape=(self.latent_dim,))\n",
        "        x = self.generator(gan_input)\n",
        "        gan_output = self.discriminator(x)\n",
        "        model = Model(gan_input, gan_output)\n",
        "        model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\")\n",
        "        return model"
      ],
      "metadata": {
        "id": "6FnIN6cvf3tL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = TextToVideoGenerator()\n",
        "\n",
        "motivational_quotes = [\n",
        "    \"Believe in yourself and all that you are.\",\n",
        "    \"You are stronger than you think.\",\n",
        "    \"The only way to do great work is to love what you do.\",\n",
        "    \"Don't watch the clock; do what it does. Keep going.\",\n",
        "]\n",
        "\n",
        "generator.generate_video(motivational_quotes)"
      ],
      "metadata": {
        "id": "7Vo-BUxJgAnl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}